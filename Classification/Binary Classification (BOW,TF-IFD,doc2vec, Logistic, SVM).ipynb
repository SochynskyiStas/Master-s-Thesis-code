{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df_complete = pd.read_csv(\"final_final_file.csv\", \n",
    "                 sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bin_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>something that i have been noticing recently i...</td>\n",
       "      <td>Catastrophizing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i went on vacation and just got back yesterday...</td>\n",
       "      <td>Catastrophizing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i've had crippling depression since i started ...</td>\n",
       "      <td>Jumping to conclusion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i feel like confusion is a huge part to depres...</td>\n",
       "      <td>Not distored</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i skipped both of my classes yesterday. i had ...</td>\n",
       "      <td>Not distored</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              sentiment  \\\n",
       "0  something that i have been noticing recently i...        Catastrophizing   \n",
       "1  i went on vacation and just got back yesterday...        Catastrophizing   \n",
       "2  i've had crippling depression since i started ...  Jumping to conclusion   \n",
       "3  i feel like confusion is a huge part to depres...           Not distored   \n",
       "4  i skipped both of my classes yesterday. i had ...           Not distored   \n",
       "\n",
       "   bin_sentiment  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1187\n",
       "0     744\n",
       "Name: bin_sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete['bin_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kdnuggets.com/2020/05/dataset-splitting-best-practices-python.html\n",
    "\n",
    "X, y = df_complete['text'], df_complete['bin_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size = 0.7, \n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOG + BOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "count_vectorizer = CountVectorizer(analyzer = \"word\", \n",
    "                                   tokenizer = nltk.word_tokenize,\n",
    "                                   preprocessor = None, \n",
    "                                   stop_words = 'english', \n",
    "                                   min_df = 3)\n",
    "\n",
    "train_data_features = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg_BOW = LogisticRegression().fit(train_data_features, y_train)\n",
    "\n",
    "test_data_features = count_vectorizer.transform(X_test)\n",
    "y_pred = log_reg_BOW.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6277    0.5291    0.5742       223\n",
      "           1     0.7321    0.8039    0.7664       357\n",
      "\n",
      "    accuracy                         0.6983       580\n",
      "   macro avg     0.6799    0.6665    0.6703       580\n",
      "weighted avg     0.6920    0.6983    0.6925       580\n",
      "\n",
      "[0.52914798 0.80392157]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid: LOG + BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed:   16.3s finished\n"
     ]
    }
   ],
   "source": [
    "penalty = ['none', 'l1', 'l2', 'elasticnet']\n",
    "C_first = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "C_second = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08]\n",
    "solver = ['liblinear', 'saga', 'newton-cg', 'lbfgs']\n",
    "\n",
    "param_grid = dict(penalty = penalty,\n",
    "                  C = C_second,\n",
    "                  solver = solver)\n",
    "\n",
    "#{'C': 0.0001, 'penalty': 'l1', 'solver': 'saga'}\n",
    "grid = GridSearchCV(estimator = log_reg_BOW,\n",
    "                    param_grid = param_grid,\n",
    "                    scoring ='f1', #'recall'; ‘accuracy’; ‘precision’, 'f1'\n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)\n",
    "grid_result = grid.fit(train_data_features, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First eun: Best Score:  0.7636214412147668\n",
    "Best Params:  {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "\n",
    "Second run: Best Score:  0.7686640959363799\n",
    "Best Params:  {'C': 0.04, 'penalty': 'l2', 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_BOW = LogisticRegression(C = 0.04, penalty ='l2', \n",
    "                                   solver = 'liblinear').fit(train_data_features, y_train)\n",
    "\n",
    "data_features = count_vectorizer.transform(X_test)\n",
    "y_pred = log_reg_BOW.predict(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7068965517241379"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.4753    0.5550       223\n",
      "           1     0.7221    0.8515    0.7815       357\n",
      "\n",
      "    accuracy                         0.7069       580\n",
      "   macro avg     0.6944    0.6634    0.6682       580\n",
      "weighted avg     0.7008    0.7069    0.6944       580\n",
      "\n",
      "Confusion Matrix : \n",
      "[[106 117]\n",
      " [ 53 304]]\n",
      "[0.47533632 0.85154062]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification log_reg_TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vect = TfidfVectorizer(min_df = 3,\n",
    "                          tokenizer = nltk.word_tokenize,\n",
    "                          preprocessor = None, \n",
    "                          stop_words = 'english')\n",
    "\n",
    "TF_IDF_train_data_features = tf_vect.fit_transform(X_train)\n",
    "\n",
    "logreg_TF_IDF = LogisticRegression().fit(TF_IDF_train_data_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features_TF_IDF = tf_vect.transform(X_test)\n",
    "y_pred = logreg_TF_IDF.predict(data_features_TF_IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6853    0.4395    0.5355       223\n",
      "           1     0.7140    0.8739    0.7859       357\n",
      "\n",
      "    accuracy                         0.7069       580\n",
      "   macro avg     0.6996    0.6567    0.6607       580\n",
      "weighted avg     0.7029    0.7069    0.6896       580\n",
      "\n",
      "[0.43946188 0.87394958]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## log_reg_TF-IDF Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    5.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7734083935075498\n",
      "Best Params:  {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:   20.9s finished\n"
     ]
    }
   ],
   "source": [
    "penalty = ['none', 'l1', 'l2', 'elasticnet']\n",
    "C_first = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "C_second = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "solver = ['liblinear', 'saga', 'newton-cg', 'lbfgs']\n",
    "\n",
    "param_grid = dict(penalty = penalty,\n",
    "                  C = C_second,\n",
    "                  solver = solver)\n",
    "\n",
    "grid = GridSearchCV(estimator = logreg_TF_IDF,\n",
    "                    param_grid = param_grid,\n",
    "                    scoring = 'f1', #'recall'; ‘accuracy’; ‘precision’\n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)\n",
    "grid_result = grid.fit(TF_IDF_train_data_features, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt:\n",
    "Best Score:  0.7734083935075498\n",
    "Best Params:  {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "\n",
    "Second attempt:\n",
    "Best Score:  0.7734083935075498\n",
    "Best Params:  {'C': 1, 'penalty': 'l2', 'solver': 'newton-cg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_TF_IDF = LogisticRegression(C = 1, penalty ='l2', \n",
    "                                   solver = 'newton-cg').fit(TF_IDF_train_data_features, y_train)\n",
    "\n",
    "data_features_TF_IDF = tf_vect.transform(X_test)\n",
    "y_pred = logreg_TF_IDF.predict(data_features_TF_IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6853    0.4395    0.5355       223\n",
      "           1     0.7140    0.8739    0.7859       357\n",
      "\n",
      "    accuracy                         0.7069       580\n",
      "   macro avg     0.6996    0.6567    0.6607       580\n",
      "weighted avg     0.7029    0.7069    0.6896       580\n",
      "\n",
      "[0.43946188 0.87394958]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 - Support Vector Machine\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM + BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6892    0.4574    0.5499       223\n",
      "           1     0.7199    0.8711    0.7883       357\n",
      "\n",
      "    accuracy                         0.7121       580\n",
      "   macro avg     0.7045    0.6643    0.6691       580\n",
      "weighted avg     0.7081    0.7121    0.6967       580\n",
      "\n",
      "[0.4573991  0.87114846]\n"
     ]
    }
   ],
   "source": [
    "svc_bow = SVC().fit(train_data_features, y_train)\n",
    "\n",
    "test_data_features = count_vectorizer.transform(X_test)\n",
    "y_pred = svc_bow.predict(test_data_features)\n",
    "\n",
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid:SVM + BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.7623286121848878\n",
      "Best Params:  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "C_second = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "gamma = [0.0001, 0.001, 0.01, 0.00001, 0.000001, 0.00000001]\n",
    "gamma_second = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009]\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid'] #‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "\n",
    "param_grid = dict(C = C,\n",
    "                  gamma = gamma,\n",
    "                  kernel = kernel)\n",
    "\n",
    "grid = GridSearchCV(estimator = svc_bow,\n",
    "                    param_grid = param_grid,\n",
    "                    scoring = 'f1', #'recall'; ‘accuracy’; ‘precision’\n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)\n",
    "grid_result = grid.fit(train_data_features, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run: Best Score:  0.7658457534195632\n",
    "Best Params:  {'C': 100, 'gamma': 0.0003, 'kernel': 'sigmoid'}\n",
    "\n",
    "Second run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_bow = SVC().fit(train_data_features, y_train)\n",
    "\n",
    "test_data_features = count_vectorizer.transform(X_test)\n",
    "y_pred = svc_bow.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM + tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tfidf = SVC().fit(TF_IDF_train_data_features, y_train)\n",
    "data_features_TF_IDF = tf_vect.transform(X_test)\n",
    "y_pred = svc_tfidf.predict(data_features_TF_IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6861    0.4215    0.5222       223\n",
      "           1     0.7088    0.8796    0.7850       357\n",
      "\n",
      "    accuracy                         0.7034       580\n",
      "   macro avg     0.6975    0.6505    0.6536       580\n",
      "weighted avg     0.7001    0.7034    0.6840       580\n",
      "\n",
      "[0.42152466 0.87955182]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid:SVM + tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-618a921206d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     n_jobs = -1)\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTF_IDF_train_data_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best Score: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "C_second = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "gamma = [0.0001, 0.001, 0.01, 0.00001, 0.000001, 0.00000001]\n",
    "gamma_second = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009]\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid'] #‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
    "\n",
    "param_grid = dict(C = C,\n",
    "                  gamma = gamma_second,\n",
    "                  kernel = kernel)\n",
    "\n",
    "grid = GridSearchCV(estimator = svc_tfidf,\n",
    "                    param_grid = param_grid,\n",
    "                    scoring = 'f1', #'recall'; ‘accuracy’; ‘precision’\n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)\n",
    "grid_result = grid.fit(TF_IDF_train_data_features, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt (C+gamma):\n",
    "Best Score:  0.7621745438286351\n",
    "Best Params:  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "\n",
    "Second attempt (C_second + gamma):\n",
    "Best Score:  0.7748284594685082\n",
    "Best Params:  {'C': 5000, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
    "\n",
    "Third attempt(C_second + gamma_second):\n",
    "Best Score:  0.7748284594685082\n",
    "Best Params:  {'C': 1000, 'gamma': 0.0005, 'kernel': 'sigmoid'}\n",
    "\n",
    "4th attempt (C+gamma_second):\n",
    "Best Score:  0.7748284594685082\n",
    "Best Params:  {'C': 1000, 'gamma': 0.0005, 'kernel': 'sigmoid'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_tfidf = SVC(C = 1000, \n",
    "                gamma = 0.0005, kernel = 'sigmoid').fit(TF_IDF_train_data_features, y_train)\n",
    "data_features_TF_IDF = tf_vect.transform(X_test)\n",
    "y_pred = svc_tfidf.predict(data_features_TF_IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7023    0.4126    0.5198       223\n",
      "           1     0.7082    0.8908    0.7891       357\n",
      "\n",
      "    accuracy                         0.7069       580\n",
      "   macro avg     0.7053    0.6517    0.6544       580\n",
      "weighted avg     0.7060    0.7069    0.6855       580\n",
      "\n",
      "[0.41255605 0.8907563 ]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df_complete)\n",
    "\n",
    "train_tagged = train_data.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['text']), \n",
    "                             tags=[r['bin_sentiment']]), axis = 1)\n",
    "\n",
    "test_tagged = test_data.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['text']), \n",
    "                             tags=[r['bin_sentiment']]), axis = 1)\n",
    "\n",
    "trainsent = train_tagged.values\n",
    "\n",
    "doc2vec_model = Doc2Vec(trainsent, \n",
    "                        vector_size = 300, \n",
    "                        window = 5, #The maximum distance between the current and predicted word within a sentence. \n",
    "                        workers = 4,\n",
    "                        epochs = 50,\n",
    "                        dm = 1)\n",
    "\n",
    "testsent = test_tagged.values\n",
    "y_train, X_train = zip(*[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in trainsent])\n",
    "y_test, X_test = zip(*[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in testsent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_doc2vec = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = logreg_doc2vec.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6014    0.4564    0.5190       195\n",
      "           1     0.6836    0.7951    0.7352       288\n",
      "\n",
      "    accuracy                         0.6584       483\n",
      "   macro avg     0.6425    0.6258    0.6271       483\n",
      "weighted avg     0.6504    0.6584    0.6479       483\n",
      "\n",
      "[0.45641026 0.79513889]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid: log + doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 450 tasks      | elapsed:  3.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9141558036022648\n",
      "Best Params:  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  5.7min finished\n"
     ]
    }
   ],
   "source": [
    "penalty = ['none', 'l1', 'l2', 'elasticnet']\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "C_second = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "C_third = [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "solver = ['liblinear', 'saga', 'newton-cg', 'lbfgs']\n",
    "\n",
    "param_grid = dict(penalty = penalty,\n",
    "                  C = C_third,\n",
    "                  solver = solver)\n",
    "\n",
    "grid = GridSearchCV(estimator = logreg_doc2vec,\n",
    "                    param_grid = param_grid,\n",
    "                    scoring ='f1', #'recall'; ‘accuracy’; ‘precision’\n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First iteration\n",
    "Best Score:  0.9141558036022648\n",
    "Best Params:  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "\n",
    "Second iteration\n",
    "Best Score:  0.9141558036022648\n",
    "Best Params:  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "\n",
    "Third iteration\n",
    "Best Score:  0.9141558036022648\n",
    "Best Params:  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_doc2vec = LogisticRegression(C = 10, penalty = 'l2', \n",
    "                                    solver = 'liblinear').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg_doc2vec.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5844    0.4615    0.5158       195\n",
      "           1     0.6809    0.7778    0.7261       288\n",
      "\n",
      "    accuracy                         0.6501       483\n",
      "   macro avg     0.6326    0.6197    0.6209       483\n",
      "weighted avg     0.6419    0.6501    0.6412       483\n",
      "\n",
      "[0.46153846 0.77777778]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM + doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_doc2vec = SVC().fit(X_train, y_train)\n",
    "y_pred = SVM_doc2vec.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6519    0.4513    0.5333       195\n",
      "           1     0.6925    0.8368    0.7579       288\n",
      "\n",
      "    accuracy                         0.6812       483\n",
      "   macro avg     0.6722    0.6440    0.6456       483\n",
      "weighted avg     0.6761    0.6812    0.6672       483\n",
      "\n",
      "[0.45128205 0.83680556]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid: SVM + doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.9155718555831166\n",
      "Best Params:  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "C_second = [1, 2, 3, 5, 6, 7, 8, 9]\n",
    "gamma = [0.0001, 0.001, 0.01, 0.00001, 0.000001]\n",
    "gamma_second = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "param_grid = dict(C = C,\n",
    "                  gamma = gamma_second,\n",
    "                  kernel = kernel)\n",
    "\n",
    "grid = GridSearchCV(estimator = SVM_doc2vec,\n",
    "                    param_grid = param_grid,\n",
    "                    scoring = 'f1',\n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "First iteration (C + gamma)\n",
    "Best Score:  0.9155718555831166\n",
    "Best Params:  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
    "\n",
    "Second iteration (C_second + gamma)\n",
    "Best Score:  0.9155718555831166\n",
    "Best Params:  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
    "\n",
    "Third iteration (C_second + gamma_second)\n",
    "Best Score:  0.9155718555831166\n",
    "Best Params:  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_doc2vec = SVC(C = 1, gamma = 0.0001, kernel = \"linear\").fit(X_train, y_train)\n",
    "y_pred = SVM_doc2vec.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5828    0.4513    0.5087       195\n",
      "           1     0.6777    0.7812    0.7258       288\n",
      "\n",
      "    accuracy                         0.6480       483\n",
      "   macro avg     0.6302    0.6163    0.6172       483\n",
      "weighted avg     0.6394    0.6480    0.6381       483\n",
      "\n",
      "[0.45128205 0.78125   ]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, digits = 4))\n",
    "\n",
    "#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,y_pred)))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
