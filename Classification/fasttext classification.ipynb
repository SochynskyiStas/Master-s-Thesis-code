{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources used:\n",
    "- Instalation: https://medium.com/@oleg.tarasov/building-fasttext-python-wrapper-from-source-under-windows-68e693a68cbb\n",
    "https://fasttext.cc/docs/en/supervised-tutorial.html\n",
    "\n",
    "https://ravindraelicherla.medium.com/build-your-own-text-classification-in-less-than-25-lines-of-code-using-fasttext-dae7229f80f9\n",
    "\n",
    "https://www.youtube.com/watch?v=TmfIcqxMdbc\n",
    "\n",
    "https://medium.com/@oleg.tarasov/building-fasttext-python-wrapper-from-source-under-windows-68e693a68cbb \n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    \n",
    "https://www.youtube.com/watch?v=tAxrlAVw-Tk&t=43s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fasttext\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv(\"final_final_file.csv\", \n",
    "                 sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_label_list = []\n",
    "temp_list = df['sentiment'].to_list()\n",
    "for i in temp_list:\n",
    "    if (i == 'Not distored'):\n",
    "        bin_label_list.append('Not distored') #'Not distored'\n",
    "    else:\n",
    "        bin_label_list.append('Distored') #'Distored'\n",
    "\n",
    "df['bin_sentiment'] = bin_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bin_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>something that i have been noticing recently i...</td>\n",
       "      <td>Catastrophizing</td>\n",
       "      <td>Distored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i went on vacation and just got back yesterday...</td>\n",
       "      <td>Catastrophizing</td>\n",
       "      <td>Distored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i've had crippling depression since i started ...</td>\n",
       "      <td>Jumping to conclusion</td>\n",
       "      <td>Distored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i feel like confusion is a huge part to depres...</td>\n",
       "      <td>Not distored</td>\n",
       "      <td>Not distored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i skipped both of my classes yesterday. i had ...</td>\n",
       "      <td>Not distored</td>\n",
       "      <td>Not distored</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              sentiment  \\\n",
       "0  something that i have been noticing recently i...        Catastrophizing   \n",
       "1  i went on vacation and just got back yesterday...        Catastrophizing   \n",
       "2  i've had crippling depression since i started ...  Jumping to conclusion   \n",
       "3  i feel like confusion is a huge part to depres...           Not distored   \n",
       "4  i skipped both of my classes yesterday. i had ...           Not distored   \n",
       "\n",
       "  bin_sentiment  \n",
       "0      Distored  \n",
       "1      Distored  \n",
       "2      Distored  \n",
       "3  Not distored  \n",
       "4  Not distored  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kdnuggets.com/2020/05/dataset-splitting-best-practices-python.html\n",
    "\n",
    "X, y = df['text'], df['bin_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size = 0.7, \n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = pd.DataFrame()\n",
    "new_df_train['label'] = y_train\n",
    "new_df_train['texts'] = X_train\n",
    "\n",
    "new_df_train['label']=['__label__'+s.replace(' or ', '$').replace(', or ','$').replace(',','$').replace(' ','_').replace(',','__label__').replace('$$','$').replace('$',' __label__').replace('___','__') for s in new_df_train['label']]\n",
    "new_df_train['label']\n",
    "\n",
    "new_df_train['texts']= new_df_train['texts'].replace('\\n',' ', regex=True).replace('\\t',' ', regex=True)\n",
    "\n",
    "new_df_train.to_csv(\"cog_bin_train.txt\", sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test = pd.DataFrame()\n",
    "new_df_test['label'] = y_test\n",
    "new_df_test['texts'] = X_test\n",
    "\n",
    "new_df_test['label']=['__label__'+s.replace(' or ', '$').replace(', or ','$').replace(',','$').replace(' ','_').replace(',','__label__').replace('$$','$').replace('$',' __label__').replace('___','__') for s in new_df_test['label']]\n",
    "new_df_test['label']\n",
    "\n",
    "new_df_test['texts']= new_df_test['texts'].replace('\\n',' ', regex=True).replace('\\t',' ', regex=True)\n",
    "\n",
    "new_df_test.to_csv(\"cog__bin_test.txt\", sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fasttext.train_supervised(input = \"cog_bin_train.txt\", lr=0.69, epoch = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 0.7189655172413794, 0.7189655172413794)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.test(\"cog__bin_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[287,  70],\n",
       "       [ 95, 128]], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list = new_df_test[\"texts\"].to_list()\n",
    "temp = pd.DataFrame()\n",
    "temp[\"predicted\"] = new_df_test[\"texts\"].apply(lambda x: ft_model.predict(x)[0][0])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(new_df_test['label'], temp[\"predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "    __label__Distored     0.7513    0.8039    0.7767       357\n",
      "__label__Not_distored     0.6465    0.5740    0.6081       223\n",
      "\n",
      "             accuracy                         0.7155       580\n",
      "            macro avg     0.6989    0.6890    0.6924       580\n",
      "         weighted avg     0.7110    0.7155    0.7119       580\n",
      "\n",
      "[0.80392157 0.57399103]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(new_df_test['label'], temp[\"predicted\"], digits = 4))\n",
    "\n",
    "cm = confusion_matrix(new_df_test['label'], temp[\"predicted\"])\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_df = df[df['sentiment'] != 'Not distored']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kdnuggets.com/2020/05/dataset-splitting-best-practices-python.html\n",
    "\n",
    "X, y = mult_df['text'], mult_df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size = 0.7, \n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_train = pd.DataFrame()\n",
    "new_df_train['label'] = y_train\n",
    "new_df_train['texts'] = X_train\n",
    "\n",
    "new_df_train['label']=['__label__'+s.replace(' or ', '$').replace(', or ','$').replace(',','$').replace(' ','_').replace(',','__label__').replace('$$','$').replace('$',' __label__').replace('___','__') for s in new_df_train['label']]\n",
    "new_df_train['label']\n",
    "\n",
    "new_df_train['texts']= new_df_train['texts'].replace('\\n',' ', regex=True).replace('\\t',' ', regex=True)\n",
    "\n",
    "new_df_train.to_csv(\"cog_multi_train.txt\", sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test = pd.DataFrame()\n",
    "new_df_test['label'] = y_test\n",
    "new_df_test['texts'] = X_test\n",
    "\n",
    "new_df_test['label']=['__label__'+s.replace(' or ', '$').replace(', or ','$').replace(',','$').replace(' ','_').replace(',','__label__').replace('$$','$').replace('$',' __label__').replace('___','__') for s in new_df_test['label']]\n",
    "new_df_test['label']\n",
    "\n",
    "new_df_test['texts']= new_df_test['texts'].replace('\\n',' ', regex=True).replace('\\t',' ', regex=True)\n",
    "\n",
    "new_df_test.to_csv(\"cog__multi_test.txt\", sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357, 0.27450980392156865, 0.27450980392156865)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model = fasttext.train_supervised(input = \"cog_multi_train.txt\", lr = 1,\n",
    "                                     epoch = 5)\n",
    "\n",
    "ft_model.test(\"cog__multi_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  0,  0, 19, 18,  2,  0,  3,  0],\n",
       "       [ 5,  0,  0,  5, 10,  3,  0,  6,  0],\n",
       "       [ 1,  0,  0, 15,  9,  2,  0,  7,  0],\n",
       "       [ 3,  0,  0, 31, 18,  1,  0,  0,  1],\n",
       "       [ 4,  0,  0, 21, 25,  4,  0,  1,  2],\n",
       "       [ 0,  0,  0,  9, 10, 13,  0,  1,  2],\n",
       "       [ 4,  0,  0, 16, 17,  0,  0,  4,  0],\n",
       "       [ 4,  0,  0,  2, 14,  1,  1,  8,  1],\n",
       "       [ 0,  0,  0,  7,  3,  2,  0,  2, 11]], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list = new_df_test[\"texts\"].to_list()\n",
    "temp = pd.DataFrame()\n",
    "temp[\"predicted\"] = new_df_test[\"texts\"].apply(lambda x: ft_model.predict(x)[0][0])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(new_df_test['label'], temp[\"predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      " __label__Black_and_white_thinking.     0.3000    0.1765    0.2222        51\n",
      "           __label__Catastrophizing     0.0000    0.0000    0.0000        29\n",
      "__label__Disqualifying_the_positive     0.0000    0.0000    0.0000        34\n",
      "       __label__Emotional_reasoning     0.2480    0.5741    0.3464        54\n",
      "     __label__Jumping_to_conclusion     0.2016    0.4386    0.2762        57\n",
      "                  __label__Labeling     0.4643    0.3714    0.4127        35\n",
      "       __label__Over-generalization     0.0000    0.0000    0.0000        41\n",
      "           __label__Personalization     0.2500    0.2581    0.2540        31\n",
      "         __label__Should_statements     0.6471    0.4400    0.5238        25\n",
      "\n",
      "                           accuracy                         0.2717       357\n",
      "                          macro avg     0.2346    0.2510    0.2261       357\n",
      "                       weighted avg     0.2251    0.2717    0.2274       357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(new_df_test['label'], temp[\"predicted\"], digits = 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
